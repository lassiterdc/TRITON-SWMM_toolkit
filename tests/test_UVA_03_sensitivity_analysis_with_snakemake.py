import pytest
import tests.utils_for_testing as tst_ut

pytestmark = pytest.mark.skipif(not tst_ut.on_UVA_HPC(), reason="Only runs on UVA HPC")

# ijob \
#   -A quinnlab \
#   -p standard \
#   --time=08:00:00 \
#   -N 1 \
#  --cpus-per-task=1 \
#  --ntasks-per-node=96

# ijob \
#   -A quinnlab \
#   -p interactive \
#   --time=08:00:00 \
#   -N 1 \
#  --cpus-per-task=1 \
#  --ntasks-per-node=24

#   --gres=gpu:1 \

# module purge
# module load gompi/14.2.0_5.0.7 miniforge
# conda activate triton_swmm_toolkit
# export PYTHONNOUSERSITE=1


def test_snakemake_sensitivity_workflow_generation_and_write(
    norfolk_uva_sensitivity_analysis,
):
    """
    Test Snakemake workflow generation for sensitivity analysis.

    Verifies that:
    1. Sub-analysis Snakefiles are generated and written correctly
    2. Master Snakefile is generated and written correctly
    3. Master Snakefile contains required rules and flags
    """
    analysis = norfolk_uva_sensitivity_analysis

    assert analysis.cfg_analysis.toggle_sensitivity_analysis is True
    assert hasattr(analysis, "sensitivity")

    sensitivity = analysis.sensitivity

    assert len(sensitivity.sub_analyses) > 0

    for sub_analysis in sensitivity.sub_analyses.values():
        snakefile_content = sub_analysis._workflow_builder.generate_snakefile_content(
            process_system_level_inputs=False,
            compile_TRITON_SWMM=True,
            prepare_scenarios=True,
            process_timeseries=True,
        )

        tst_ut.assert_snakefile_has_rules(
            snakefile_content, ["all", "setup", "simulation", "consolidate"]
        )

        sub_snakefile_path = tst_ut.write_snakefile(sub_analysis, snakefile_content)
        tst_ut.assert_file_exists(sub_snakefile_path, "Sub-analysis Snakefile")
        assert len(sub_snakefile_path.read_text()) > 100

    master_snakefile_content = (
        sensitivity._workflow_builder.generate_master_snakefile_content(
            which="both",
            overwrite_outputs_if_already_created=False,
            compression_level=5,
        )
    )

    tst_ut.assert_snakefile_has_rules(
        master_snakefile_content,
        ["all", "master_consolidation", "simulation_sa", "consolidate_"],
    )
    tst_ut.assert_snakefile_has_flags(
        master_snakefile_content,
        [
            "--consolidate-sensitivity-analysis-outputs",
        ],
    )

    num_sub_analyses = len(sensitivity.sub_analyses)
    for sa_id in range(num_sub_analyses):
        assert f"rule consolidate_sa_{sa_id}:" in master_snakefile_content

    master_snakefile_path = tst_ut.write_snakefile(analysis, master_snakefile_content)
    tst_ut.assert_file_exists(master_snakefile_path, "Master Snakefile")
    assert len(master_snakefile_path.read_text()) > 100


@pytest.mark.parametrize(
    "config,expected_flags",
    [
        (
            {
                "which": "TRITON",
                "overwrite_outputs_if_already_created": True,
                "compression_level": 7,
            },
            [
                "--compression-level 7",
                "--which TRITON",
                "--overwrite-outputs-if-already-created",
                "--consolidate-sensitivity-analysis-outputs",
            ],
        ),
        (
            {
                "which": "both",
                "overwrite_outputs_if_already_created": False,
                "compression_level": 5,
            },
            [
                "--compression-level 5",
                "--which both",
                "--consolidate-sensitivity-analysis-outputs",
            ],
        ),
    ],
)
def test_snakemake_sensitivity_workflow_config_generation(
    norfolk_uva_sensitivity_analysis, config, expected_flags
):
    """
    Test configuration passed to Snakemake for sensitivity analysis on UVA HPC.

    Verifies that:
    1. All parameters are correctly formatted in master Snakefile
    2. Consolidation command includes correct flags
    3. Sub-analysis references are correct
    """
    analysis = norfolk_uva_sensitivity_analysis
    sensitivity = analysis.sensitivity

    master_snakefile_content = (
        sensitivity._workflow_builder.generate_master_snakefile_content(**config)
    )

    tst_ut.assert_snakefile_has_flags(
        master_snakefile_content,
        expected_flags
        + [
            f"--system-config {analysis._system.system_config_yaml}",
            f"--analysis-config {analysis.analysis_config_yaml}",
        ],
    )


def test_snakemake_sensitivity_workflow_dry_run(
    norfolk_uva_sensitivity_analysis,
):
    """
    Test Snakemake dry-run for sensitivity analysis (--dry-run flag) on UVA HPC.

    Validates that:
    1. DAG can be constructed from master Snakefile
    2. All dependencies resolve correctly
    3. No actual execution occurs
    4. Snakemake exit code is 0
    """
    analysis = norfolk_uva_sensitivity_analysis
    result = analysis.submit_workflow(
        mode="slurm",
        process_system_level_inputs=True,
        overwrite_system_inputs=True,
        compile_TRITON_SWMM=True,
        recompile_if_already_done_successfully=True,
        prepare_scenarios=True,
        overwrite_scenario_if_already_set_up=True,
        rerun_swmm_hydro_if_outputs_exist=True,
        process_timeseries=True,
        which="both",
        clear_raw_outputs=True,
        overwrite_outputs_if_already_created=True,
        compression_level=5,
        pickup_where_leftoff=False,
        dry_run=True,
        verbose=True,
    )

    assert result.get(
        "success"
    ), f"Snakemake dry-run failed: {result.get('message', '')}"
    assert result.get("mode") == "slurm"


@pytest.mark.slow
def test_snakemake_sensitivity_workflow_execution(
    norfolk_uva_sensitivity_analysis,
):
    """
    Test Snakemake sensitivity analysis workflow execution on UVA HPC with SLURM.

    Validates that:
    1. submit_workflow() returns success
    2. Setup phase completes for each sub-analysis
    3. All simulations execute without errors
    4. Sub-analysis consolidation completes
    5. Master consolidation completes
    6. Final sensitivity analysis summaries are generated
    """
    analysis = norfolk_uva_sensitivity_analysis
    which = "both"

    result = analysis.submit_workflow(
        mode="slurm",
        process_system_level_inputs=True,
        overwrite_system_inputs=False,
        compile_TRITON_SWMM=True,
        recompile_if_already_done_successfully=False,
        prepare_scenarios=True,
        overwrite_scenario_if_already_set_up=False,
        rerun_swmm_hydro_if_outputs_exist=True,
        process_timeseries=True,
        which=which,
        clear_raw_outputs=True,
        overwrite_outputs_if_already_created=False,
        compression_level=5,
        pickup_where_leftoff=False,
        verbose=True,
        wait_for_completion=True,
    )

    # Verify workflow submission was successful
    assert result["success"], f"Workflow submission failed: {result.get('message', '')}"
    assert result["mode"] == "slurm", "Should be running in SLURM mode"

    # Note: On SLURM, the workflow is submitted but may not complete immediately
    # We would need to poll for completion or check logs
    # For now, we just verify successful submission

    tst_ut.assert_analysis_workflow_completed_successfully(analysis)
